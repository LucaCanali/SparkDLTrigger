{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traininig the Inclusive classifier with tf.Keras using data in TFRecord format\n",
    "\n",
    "**tf.keras Inclusive classifier** This notebooks trains a neural network for the particle classifier using the Inclusive Classifier, using as input the list of recunstructed particles with the low level features + the high level features. Data is prepared from Parquet using Apache Spark, and written into TFRecord format. Data in TFRecord format is read from TensorFlow using tf.data and tf.io in tf.keras.\n",
    "\n",
    "To run this notebook we used the following configuration:\n",
    "* *Software stack*: TensorFlow 2.0.0-rc0\n",
    "* *Platform*: CentOS 7, Python 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local1/lucatests/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/local1/lucatests/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/local1/lucatests/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/local1/lucatests/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/local1/lucatests/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/local1/lucatests/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Sequential, Input, Model\n",
    "from tensorflow.keras.layers import Masking, Dense, Activation, GRU, Dropout, concatenate\n",
    "\n",
    "tf.version.VERSION\n",
    "# only needed for TensorFlow 1.x\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure distributed training using tf.distribute\n",
    "This notebook shows an example of distributed training with tf.keras using 3 concurrent executions on a single machine.\n",
    "The test machine has 24 physical cores it has been notes that a serial execution of the training would leave spare capacity. With distributed training we can \"use all the CPU on the box\". \n",
    "- TensorFlow MultiWorkerMirroredStrategy is used to distribute the training.\n",
    "- Configuration of the workers is done using the OS enviroment variable **TF_CONFIG**.\n",
    "- **nodes_endpoints** configures the list of machines and ports that will be used. In this example, we use 3 workers on the same machines, you can use this to distribute over multiple machines too\n",
    "- **worker_number** will be unique for each worker, numbering starts from 0\n",
    "- Worker number 0 will be the master. \n",
    "- You need to run the 3 notebooks for the 3 configured workers at the same time (training will only start when all 3 workers are active) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each worker will have a unique worker_number, numbering starts from 0\n",
    "worker_number=2\n",
    "\n",
    "nodes_endpoints = [\"localhost:12345\", \"localhost:12346\", \"localhost:12347\", \"localhost:12348\"]\n",
    "number_workers = len(nodes_endpoints)\n",
    "\n",
    "import os\n",
    "import json\n",
    "os.environ['TF_CONFIG'] = json.dumps({\n",
    "    'cluster': {\n",
    "        'worker': nodes_endpoints\n",
    "    },\n",
    "    'task': {'type': 'worker', 'index': worker_number}\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Keras model for the inclusive classifier hooking with tf.distribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0902 11:12:59.660098 140053501286208 deprecation.py:323] From /local1/lucatests/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:3983: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# This implements the distributed stratedy for model\n",
    "with strategy.scope():\n",
    "    ## GRU branch\n",
    "    gru_input = Input(shape=(801,19), name='gru_input')\n",
    "    a = gru_input\n",
    "    a = Masking(mask_value=0.)(a)\n",
    "    a = GRU(units=50,activation='tanh')(a)\n",
    "    gruBranch = Dropout(0.2)(a)\n",
    "    \n",
    "    hlf_input = Input(shape=(14), name='hlf_input')\n",
    "    b = hlf_input\n",
    "    hlfBranch = Dropout(0.2)(b)\n",
    "\n",
    "    c = concatenate([gruBranch, hlfBranch])\n",
    "    c = Dense(25, activation='relu')(c)\n",
    "    output = Dense(3, activation='softmax')(c)\n",
    "    \n",
    "    model = Model(inputs=[gru_input, hlf_input], outputs=output)\n",
    "    \n",
    "    ## Compile model\n",
    "    optimizer = 'Adam'\n",
    "    loss = 'categorical_crossentropy'\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "gru_input (InputLayer)          [(None, 801, 19)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, 801, 19)      0           gru_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 50)           10650       masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hlf_input (InputLayer)          [(None, 14)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 50)           0           gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14)           0           hlf_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 25)           1625        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            78          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 12,353\n",
      "Trainable params: 12,353\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test and training data in TFRecord format, using tf.data and tf.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/local3/lucatests/Data/\"\n",
    "\n",
    "# test dataset \n",
    "files_test_dataset = tf.data.Dataset.list_files(PATH + \"testUndersampled.tfrecord/part-r*\", shuffle=False)\n",
    "\n",
    "# training dataset \n",
    "files_train_dataset = tf.data.Dataset.list_files(PATH + \"trainUndersampled.tfrecord/part-r*\", seed=4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunable\n",
    "num_parallel_reads=tf.data.experimental.AUTOTUNE # TF2.0\n",
    "# num_parallel_reads=8\n",
    "\n",
    "test_dataset = files_test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE).interleave(\n",
    "    tf.data.TFRecordDataset, \n",
    "    cycle_length=num_parallel_reads,\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "train_dataset = files_train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE).interleave(\n",
    "    tf.data.TFRecordDataset, cycle_length=num_parallel_reads,\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decode TF records into the required features and labels\n",
    "def decode(serialized_example):\n",
    "    deser_features = tf.io.parse_single_example(\n",
    "      serialized_example,\n",
    "      # Defaults are not specified since both keys are required.\n",
    "      features={\n",
    "          'HLF_input': tf.io.FixedLenFeature((14), tf.float32),\n",
    "          'GRU_input': tf.io.FixedLenFeature((801,19), tf.float32),\n",
    "          'encoded_label': tf.io.FixedLenFeature((3), tf.float32),\n",
    "          })\n",
    "    return((deser_features['GRU_input'], deser_features['HLF_input']), deser_features['encoded_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for debugging\n",
    "# for record in test_dataset.take(1):\n",
    "#     print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_test_dataset=test_dataset.map(decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "parsed_train_dataset=train_dataset.map(decode, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for debugging\n",
    "# Show and example of the parsed data\n",
    "# for record in parsed_test_dataset.take(1):\n",
    "#    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: (((None, 801, 19), (None, 14)), (None, 3)), types: ((tf.float32, tf.float32), tf.float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tunable\n",
    "batch_size = 64 * number_workers\n",
    "\n",
    "train=parsed_train_dataset.repeat().batch(batch_size)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13383"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_samples=3426083   # there are 3426083 samples in the training dataset\n",
    "\n",
    "steps_per_epoch=num_train_samples//batch_size\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunable\n",
    "validation_batch_size=1024\n",
    "\n",
    "test=parsed_test_dataset.repeat().batch(validation_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test_samples=856090 # there are 856090 samples in the test dataset\n",
    "\n",
    "validation_steps=num_test_samples//validation_batch_size \n",
    "validation_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the tf.keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0902 11:13:40.562420 140053501286208 distribute_coordinator.py:825] `eval_fn` is not passed in. The `worker_fn` will be used if an \"evaluator\" task exists in the cluster.\n",
      "W0902 11:13:40.563970 140053501286208 distribute_coordinator.py:829] `eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\n",
      "W0902 11:13:40.566562 140053501286208 distributed_training_utils.py:1163] ModelCheckpoint callback is not provided. Workers will need to restart training if any fails.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 13383 steps, validate for 836 steps\n",
      "Epoch 1/6\n",
      "13383/13383 [==============================] - 6996s 523ms/step - loss: 0.2546 - accuracy: 0.9049 - val_loss: 0.1829 - val_accuracy: 0.9324\n",
      "Epoch 2/6\n",
      "13383/13383 [==============================] - 6805s 509ms/step - loss: 0.1788 - accuracy: 0.9347 - val_loss: 0.1547 - val_accuracy: 0.9432\n",
      "Epoch 3/6\n",
      "13383/13383 [==============================] - 6803s 508ms/step - loss: 0.1575 - accuracy: 0.9427 - val_loss: 0.1393 - val_accuracy: 0.9494\n",
      "Epoch 4/6\n",
      "13383/13383 [==============================] - 6829s 510ms/step - loss: 0.1478 - accuracy: 0.9466 - val_loss: 0.1336 - val_accuracy: 0.9515\n",
      "Epoch 5/6\n",
      "13383/13383 [==============================] - 6771s 506ms/step - loss: 0.1416 - accuracy: 0.9489 - val_loss: 0.1283 - val_accuracy: 0.9536\n",
      "Epoch 6/6\n",
      "13383/13383 [==============================] - 6847s 512ms/step - loss: 0.1369 - accuracy: 0.9507 - val_loss: 0.1271 - val_accuracy: 0.9542\n",
      "CPU times: user 1d 14h 21min 36s, sys: 8h 16min 20s, total: 1d 22h 37min 56s\n",
      "Wall time: 11h 24min 11s\n"
     ]
    }
   ],
   "source": [
    "# train the Keras model\n",
    "\n",
    "# tunable\n",
    "num_epochs = 6\n",
    "\n",
    "# callbacks = [ tf.keras.callbacks.TensorBoard(log_dir='./logs') ]\n",
    "callbacks = []\n",
    "    \n",
    "%time history = model.fit(train, steps_per_epoch=steps_per_epoch, \\\n",
    "                          validation_data=test, validation_steps=validation_steps, \\\n",
    "                          epochs=num_epochs, callbacks=callbacks, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"./\"\n",
    "model.save(PATH + \"mymodel\" + str(worker_number) + \".h5\", save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF 2.0\n",
    "# tf.keras.models.save_model(model, PATH + \"mymodel\" + str(worker_number) + \".tf\", save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training history performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('seaborn-darkgrid')\n",
    "# Graph with loss vs. epoch\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"HLF classifier loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph with accuracy vs. epoch\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"HLF classifier accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance metrics\n",
    "Load the model and plot the ROC and AUC and te confusion matrix using the noteboook  \n",
    "**4.3a-Model_evaluate_ROC_and_CM.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": [
    {
     "name": "spark.dynamicAllocation.enabled",
     "value": "false"
    },
    {
     "name": "spark.executor.memory",
     "value": "14G"
    },
    {
     "name": "spark.executor.cores",
     "value": "6"
    },
    {
     "name": "spark.executor.instances",
     "value": "6"
    },
    {
     "name": "spark.driver.memory",
     "value": "10G"
    },
    {
     "name": "spark.driver.maxResultSize",
     "value": "10G"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
